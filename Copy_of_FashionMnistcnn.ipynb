{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOqy4B3tWTplq7RcpP8u2f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saliq-2/FashionMnist/blob/main/Copy_of_FashionMnistcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ffKmBU3DfrFb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data (ignore the warnings!)\n",
        "fashion_mnist = datasets.FashionMNIST('data/fashion', download=True, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "print(fashion_mnist)\n",
        "print(dir(fashion_mnist))\n",
        "print(fashion_mnist.train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRwMAHgufxKG",
        "outputId": "023d0658-44a3-4e89-9872-1dec0f5a2b76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.5MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 304kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.45MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.36MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data/fashion\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n",
            "['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_check_exists', '_check_legacy_exist', '_format_transform_repr', '_is_protocol', '_load_data', '_load_legacy_data', '_repr_indent', 'class_to_idx', 'classes', 'data', 'download', 'extra_repr', 'mirrors', 'processed_folder', 'raw_folder', 'resources', 'root', 'target_transform', 'targets', 'test_data', 'test_file', 'test_labels', 'train', 'train_data', 'train_labels', 'training_file', 'transform', 'transforms']\n",
            "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target classes\n",
        "label_dict = {\n",
        " 0: 'T-shirt/top',\n",
        " 1: 'Trouser',\n",
        " 2: 'Pullover',\n",
        " 3: 'Dress',\n",
        " 4: 'Coat',\n",
        " 5: 'Sandal',\n",
        " 6: 'Shirt',\n",
        " 7: 'Sneaker',\n",
        " 8: 'Bag',\n",
        " 9: 'Ankle boot'\n",
        "}"
      ],
      "metadata": {
        "id": "WHgpKVLjfz7k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Compute the classification accuracy for given labels and predictions\n",
        "    :param true_labels: list of gold labels\n",
        "    :param predicted_labels: list of predicted labels of same length as true_labels\n",
        "    :return: a float between 0 and 1 describing how accurate the predicted labels are\n",
        "    \"\"\"\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    true_labels = torch.tensor(true_labels)\n",
        "    predicted_labels = torch.tensor(predicted_labels)\n",
        "\n",
        "    correct = (true_labels == predicted_labels).sum().item()\n",
        "    total = len(true_labels)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    #raise NotImplementedError\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "rNve1K-Nf3bH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn network arch conv-->max pool-->conv-->max pool-->fcn-->fcn\n",
        "\n",
        "class CNNFashion(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNNFashion, self).__init__()\n",
        "    self.cnn_layer1=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=2,stride=1)\n",
        "    self.cnn_layer2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2,stride=1)\n",
        "    self.max_pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    #Activation Function\n",
        "    self.relu=nn.ReLU()\n",
        "    #Linear Layers\n",
        "    self.linear1=nn.Linear(6*6*64,1028)\n",
        "    self.linear2=nn.Linear(1028,512)\n",
        "    self.linear3=nn.Linear(512,128)\n",
        "    self.linear4=nn.Linear(128,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x=self.max_pool(self.relu(self.cnn_layer1(x)))\n",
        "\n",
        "    x=self.max_pool(self.relu(self.cnn_layer2(x)))\n",
        "\n",
        "    x=x.view(x.size(0),-1)\n",
        "\n",
        "    x=self.relu(self.linear1(x))\n",
        "\n",
        "    x=self.relu(self.linear2(x))\n",
        "\n",
        "    x=self.relu(self.linear3(x))\n",
        "\n",
        "    x=self.linear4(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zcLsImoAf4Ju"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 784  # Fashion MNIST data input (img shape: 28*28)\n",
        "n_classes = len(label_dict)  # Fashion MNIST total classes (0–9 digits)\n",
        "n_samples = fashion_mnist.train_data.shape[0]  # Number of examples in training set\n",
        "batch_size = 32\n",
        "n_epochs = 10\n",
        "summary_freq_batches = 10\n",
        "learning_rate = 0.001\n",
        "train_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "GrbywdYrJ5U_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defiining the model\n",
        "model=CNNFashion()\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a-747sArw4SY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: initialise model, optimizer and loss function\n",
        "# Training\n",
        "model=CNNFashion()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "train_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size = batch_size)\n",
        "total_count = 0\n",
        "for epoch_no in range(n_epochs):\n",
        "    running_loss=0.0\n",
        "    for batch_no, (batch_inputs, batch_labels) in enumerate(train_loader):\n",
        "\n",
        "        total_count += batch_size\n",
        "        # TODO: feed input to model, calculate loss, step with the optimizer, zero_grad\n",
        "        # YOUR CODE HERE\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(batch_inputs)\n",
        "        loss=loss_function(outputs,batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "        #if batch_no % summary_freq_batches==0:\n",
        "            # TODO: add the loss of the training batch to the training summary\n",
        "            # YOUR CODE HERE\n",
        "            #print(f\"Epoch {epoch_no}, Batch {batch_no}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    running_loss=running_loss/len(train_loader)\n",
        "\n",
        "    print(f'Epoch {epoch_no} Training Loss--- {running_loss}')\n",
        "            #raise NotImplementedError()\n",
        "\n",
        "# Test on the train set (do not do this in practice)\n",
        "\n",
        "test_inputs = fashion_mnist.data.unsqueeze(1).float()  # [60000, 1, 28, 28]\n",
        "\n",
        "test_labels = fashion_mnist.targets\n",
        "\n",
        "test_predictions = None\n",
        "# TODO: feed test inputs, fetch predictions\n",
        "# YOUR CODE HERE\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "\n",
        "    # Get model outputs (logits)\n",
        "    test_outputs = model(test_inputs.float())\n",
        "\n",
        "    # Get the predicted class by finding the index of the maximum log-probability\n",
        "    # torch.max returns (values, indices), we only need the indices\n",
        "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
        "\n",
        "# Compute the accuracy of the validation predictions\n",
        "true_test_labels = test_labels\n",
        "print(\"\\nTest accuracy after training of {} iterations: {:.2f}%\".format(total_count, accuracy(true_test_labels, test_predictions)*100))\n",
        "\n",
        "# Random test sample\n",
        "sample_no = np.random.randint(0, len(test_inputs))\n",
        "print(\"\\nTest prediction: {}\".format(label_dict[test_predictions[sample_no].item()]))\n",
        "\n",
        "plt.show()\n",
        "plt.imshow(test_inputs[sample_no].reshape(28,28), cmap='Greys')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "Lk_YSAU_xIDM",
        "outputId": "0f91da25-6477-44db-ee1f-a931e550a64c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss--- 2.2751914637247723\n",
            "Epoch 1 Training Loss--- 1.8474410091718039\n",
            "Epoch 2 Training Loss--- 0.9897183358510335\n",
            "Epoch 3 Training Loss--- 0.8325522655646006\n",
            "Epoch 4 Training Loss--- 0.7531058550198872\n",
            "Epoch 5 Training Loss--- 0.6996948992093404\n",
            "Epoch 6 Training Loss--- 0.6586118539333343\n",
            "Epoch 7 Training Loss--- 0.6238045982837677\n",
            "Epoch 8 Training Loss--- 0.5929869932333628\n",
            "Epoch 9 Training Loss--- 0.5657055218617122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-3259583533.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  true_labels = torch.tensor(true_labels)\n",
            "/tmp/ipython-input-4-3259583533.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_labels = torch.tensor(predicted_labels)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy after training of 600000 iterations: 75.65%\n",
            "\n",
            "Test prediction: Trouser\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZxDa2wHe64jE"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}