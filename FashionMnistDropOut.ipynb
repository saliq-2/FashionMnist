{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8YhFuGK5gKi/U9DpuyOcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saliq-2/FashionMnist/blob/main/FashionMnistDropOut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kHWU0z2ZsiNO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data (ignore the warnings!)\n",
        "fashion_mnist = datasets.FashionMNIST('data/fashion', download=True, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "print(fashion_mnist)\n",
        "print(dir(fashion_mnist))\n",
        "print(fashion_mnist.train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9WNeC5mt0Hp",
        "outputId": "c72b58dc-7a58-4e55-c538-7fe18c2bd8d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data/fashion\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n",
            "['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_check_exists', '_check_legacy_exist', '_format_transform_repr', '_is_protocol', '_load_data', '_load_legacy_data', '_repr_indent', 'class_to_idx', 'classes', 'data', 'download', 'extra_repr', 'mirrors', 'processed_folder', 'raw_folder', 'resources', 'root', 'target_transform', 'targets', 'test_data', 'test_file', 'test_labels', 'train', 'train_data', 'train_labels', 'training_file', 'transform', 'transforms']\n",
            "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Compute the classification accuracy for given labels and predictions\n",
        "    :param true_labels: list of gold labels\n",
        "    :param predicted_labels: list of predicted labels of same length as true_labels\n",
        "    :return: a float between 0 and 1 describing how accurate the predicted labels are\n",
        "    \"\"\"\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    true_labels = torch.tensor(true_labels)\n",
        "    predicted_labels = torch.tensor(predicted_labels)\n",
        "\n",
        "    correct = (true_labels == predicted_labels).sum().item()\n",
        "    total = len(true_labels)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    #raise NotImplementedError\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "4TlAdC5rt5a8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target classes\n",
        "label_dict = {\n",
        " 0: 'T-shirt/top',\n",
        " 1: 'Trouser',\n",
        " 2: 'Pullover',\n",
        " 3: 'Dress',\n",
        " 4: 'Coat',\n",
        " 5: 'Sandal',\n",
        " 6: 'Shirt',\n",
        " 7: 'Sneaker',\n",
        " 8: 'Bag',\n",
        " 9: 'Ankle boot'\n",
        "}"
      ],
      "metadata": {
        "id": "rJHIz70tt2rK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 784  # Fashion MNIST data input (img shape: 28*28)\n",
        "n_classes = len(label_dict)  # Fashion MNIST total classes (0â€“9 digits)\n",
        "n_samples = fashion_mnist.train_data.shape[0]  # Number of examples in training set\n",
        "batch_size = 10\n",
        "n_epochs = 5\n",
        "summary_freq_batches = 10\n",
        "learning_rate = 0.01\n",
        "train_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0kQL8i3QzF1",
        "outputId": "90acb05d-6970-49c9-bf33-dab515e461fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "IIia2TwxZ9i-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "#Network Arch\n",
        "\n",
        "#conv->maxpool->relu->droput->#conv->maxpool->relu->droput->#conv->maxpool->relu->droput->flatten->linear_layer->relu->linear_layer->softmax_layer\n",
        "class CNNDropout(nn.Module):\n",
        "   def __init__(self):\n",
        "      super(CNNDropout, self).__init__()\n",
        "\n",
        "\n",
        "      self.conv1=nn.Conv2d(in_channels=1,out_channels=10,kernel_size=3,stride=1)\n",
        "\n",
        "\n",
        "      self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,stride=1)\n",
        "\n",
        "\n",
        "      self.conv3=nn.Conv2d(in_channels=20,out_channels=40,kernel_size=3,stride=1)\n",
        "\n",
        "\n",
        "      self.dropout=nn.Dropout2d(0.2)\n",
        "\n",
        "\n",
        "\n",
        "      #Linear layers\n",
        "\n",
        "\n",
        "      self.linear1=nn.Linear(40*1*1,100)\n",
        "\n",
        "      self.linear2=nn.Linear(100,10)\n",
        "\n",
        "\n",
        "\n",
        "      #max pool\n",
        "      self.max_pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "      #activation\n",
        "\n",
        "      self.relu=nn.ReLU()\n",
        "\n",
        "   def forward(self,x):\n",
        "      #layer 1\n",
        "\n",
        "\n",
        "      x=self.relu(self.conv1(x))\n",
        "      x=self.max_pool(x)\n",
        "      x=self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "      #layer 2\n",
        "\n",
        "      x=self.conv2(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.max_pool(x)\n",
        "      x=self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "      #layer 3\n",
        "\n",
        "      x=self.conv3(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.max_pool(x)\n",
        "      x=self.dropout(x)\n",
        "\n",
        "      #print(x.shape)\n",
        "\n",
        "      x=x.view(x.size(0),-1)\n",
        "\n",
        "\n",
        "      #linear layers\n",
        "\n",
        "      x=self.linear1(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.linear2(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "#\n",
        "model=CNNDropout()\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "epochs=10"
      ],
      "metadata": {
        "id": "W8DiOSWfaHrf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs=10\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  running_loss=0.0\n",
        "  for images,labels in train_loader:\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output=model(images)\n",
        "    loss=criterion(output,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch}----- Training loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzeTCC-pfRss",
        "outputId": "3adac5e0-1f42-4eda-d351-d264f5e79e76"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0----- Training loss: 0.5127155889485342\n",
            "Epoch 1----- Training loss: 0.49308854159417875\n",
            "Epoch 2----- Training loss: 0.47813286949414757\n",
            "Epoch 3----- Training loss: 0.46489036209710566\n",
            "Epoch 4----- Training loss: 0.4538221976738423\n",
            "Epoch 5----- Training loss: 0.45272770639446874\n",
            "Epoch 6----- Training loss: 0.4437577872129623\n",
            "Epoch 7----- Training loss: 0.4407967197225274\n",
            "Epoch 8----- Training loss: 0.4392282514406834\n",
            "Epoch 9----- Training loss: 0.43682165994190536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: initialise model, optimizer and loss function\n",
        "# Training\n",
        "model=CNNDropout()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "train_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size = batch_size)\n",
        "total_count = 0\n",
        "for epoch_no in range(n_epochs):\n",
        "    for batch_no, (batch_inputs, batch_labels) in enumerate(train_loader):\n",
        "\n",
        "        total_count += batch_size\n",
        "        # TODO: feed input to model, calculate loss, step with the optimizer, zero_grad\n",
        "        # YOUR CODE HERE\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(batch_inputs)\n",
        "        loss=loss_function(outputs,batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "        #if batch_no % summary_freq_batches==0:\n",
        "            # TODO: add the loss of the training batch to the training summary\n",
        "            # YOUR CODE HERE\n",
        "            #print(f\"Epoch {epoch_no}, Batch {batch_no}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #raise NotImplementedError()\n",
        "\n",
        "# Test on the train set (do not do this in practice)\n",
        "\n",
        "test_inputs = fashion_mnist.data.unsqueeze(1).float()  # [60000, 1, 28, 28]\n",
        "\n",
        "test_labels = fashion_mnist.targets\n",
        "\n",
        "test_predictions = None\n",
        "# TODO: feed test inputs, fetch predictions\n",
        "# YOUR CODE HERE\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "\n",
        "    # Get model outputs (logits)\n",
        "    test_outputs = model(test_inputs.float())\n",
        "\n",
        "    # Get the predicted class by finding the index of the maximum log-probability\n",
        "    # torch.max returns (values, indices), we only need the indices\n",
        "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
        "\n",
        "# Compute the accuracy of the validation predictions\n",
        "true_test_labels = test_labels\n",
        "print(\"\\nTest accuracy after training of {} iterations: {:.2f}%\".format(total_count, accuracy(true_test_labels, test_predictions)*100))\n",
        "\n",
        "# Random test sample\n",
        "sample_no = np.random.randint(0, len(test_inputs))\n",
        "print(\"\\nTest prediction: {}\".format(label_dict[test_predictions[sample_no].item()]))\n",
        "\n",
        "plt.show()\n",
        "plt.imshow(test_inputs[sample_no].reshape(28,28), cmap='Greys')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "yrJMvV0Yr9iF",
        "outputId": "7fcdba74-3274-4faa-e6db-6300aa1fc090"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy after training of 300000 iterations: 81.65%\n",
            "\n",
            "Test prediction: T-shirt/top\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3259583533>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  true_labels = torch.tensor(true_labels)\n",
            "<ipython-input-5-3259583533>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_labels = torch.tensor(predicted_labels)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}