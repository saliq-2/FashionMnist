{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZWlCqfuj5kjURVCzB+rfm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saliq-2/FashionMnist/blob/main/FashionMnistDropOutupdated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kHWU0z2ZsiNO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data (ignore the warnings!)\n",
        "fashion_mnist = datasets.FashionMNIST('data/fashion', download=True, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "print(fashion_mnist)\n",
        "print(dir(fashion_mnist))\n",
        "print(fashion_mnist.train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9WNeC5mt0Hp",
        "outputId": "78c5f6b1-9edc-4566-b11f-d9a8da5edfe9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data/fashion\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n",
            "['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_check_exists', '_check_legacy_exist', '_format_transform_repr', '_is_protocol', '_load_data', '_load_legacy_data', '_repr_indent', 'class_to_idx', 'classes', 'data', 'download', 'extra_repr', 'mirrors', 'processed_folder', 'raw_folder', 'resources', 'root', 'target_transform', 'targets', 'test_data', 'test_file', 'test_labels', 'train', 'train_data', 'train_labels', 'training_file', 'transform', 'transforms']\n",
            "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:76: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Compute the classification accuracy for given labels and predictions\n",
        "    :param true_labels: list of gold labels\n",
        "    :param predicted_labels: list of predicted labels of same length as true_labels\n",
        "    :return: a float between 0 and 1 describing how accurate the predicted labels are\n",
        "    \"\"\"\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    true_labels = torch.tensor(true_labels)\n",
        "    predicted_labels = torch.tensor(predicted_labels)\n",
        "\n",
        "    correct = (true_labels == predicted_labels).sum().item()\n",
        "    total = len(true_labels)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    #raise NotImplementedError\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "4TlAdC5rt5a8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target classes\n",
        "label_dict = {\n",
        " 0: 'T-shirt/top',\n",
        " 1: 'Trouser',\n",
        " 2: 'Pullover',\n",
        " 3: 'Dress',\n",
        " 4: 'Coat',\n",
        " 5: 'Sandal',\n",
        " 6: 'Shirt',\n",
        " 7: 'Sneaker',\n",
        " 8: 'Bag',\n",
        " 9: 'Ankle boot'\n",
        "}"
      ],
      "metadata": {
        "id": "rJHIz70tt2rK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 784  # Fashion MNIST data input (img shape: 28*28)\n",
        "n_classes = len(label_dict)  # Fashion MNIST total classes (0â€“9 digits)\n",
        "n_samples = fashion_mnist.train_data.shape[0]  # Number of examples in training set\n",
        "batch_size = 32\n",
        "n_epochs = 10\n",
        "summary_freq_batches = 10\n",
        "learning_rate = 0.01\n",
        "train_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "u0kQL8i3QzF1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IIia2TwxZ9i-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "#Network Arch\n",
        "\n",
        "#conv->maxpool->relu->droput->#conv->maxpool->relu->droput->#conv->maxpool->relu->droput->flatten->linear_layer->relu->linear_layer->softmax_layer\n",
        "class CNNDropout(nn.Module):\n",
        "   def __init__(self):\n",
        "      super(CNNDropout, self).__init__()\n",
        "\n",
        "\n",
        "      self.conv1=nn.Conv2d(in_channels=1,out_channels=10,kernel_size=3,stride=1)\n",
        "\n",
        "\n",
        "      self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=3,stride=1)\n",
        "\n",
        "\n",
        "      self.conv3=nn.Conv2d(in_channels=20,out_channels=40,kernel_size=3,stride=1)\n",
        "\n",
        "\n",
        "      self.dropout=nn.Dropout2d(0.2)\n",
        "\n",
        "\n",
        "\n",
        "      #Linear layers\n",
        "\n",
        "\n",
        "      self.linear1=nn.Linear(40*1*1,100)\n",
        "\n",
        "      self.linear2=nn.Linear(100,10)\n",
        "\n",
        "\n",
        "\n",
        "      #max pool\n",
        "      self.max_pool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "      #activation\n",
        "\n",
        "      self.relu=nn.ReLU()\n",
        "\n",
        "   def forward(self,x):\n",
        "      #layer 1\n",
        "\n",
        "\n",
        "      x=self.relu(self.conv1(x))\n",
        "      x=self.max_pool(x)\n",
        "      x=self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "      #layer 2\n",
        "\n",
        "      x=self.conv2(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.max_pool(x)\n",
        "      x=self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "      #layer 3\n",
        "\n",
        "      x=self.conv3(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.max_pool(x)\n",
        "      x=self.dropout(x)\n",
        "\n",
        "      #print(x.shape)\n",
        "\n",
        "      x=x.view(x.size(0),-1)\n",
        "\n",
        "\n",
        "      #linear layers\n",
        "\n",
        "      x=self.linear1(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.linear2(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: initialise model, optimizer and loss function\n",
        "# Training\n",
        "model=CNNDropout()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "train_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size = batch_size)\n",
        "total_count = 0\n",
        "for epoch_no in range(n_epochs):\n",
        "    running_loss=0.0\n",
        "    for batch_no, (batch_inputs, batch_labels) in enumerate(train_loader):\n",
        "\n",
        "        total_count += batch_size\n",
        "        # TODO: feed input to model, calculate loss, step with the optimizer, zero_grad\n",
        "        # YOUR CODE HERE\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(batch_inputs)\n",
        "        loss=loss_function(outputs,batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "        #if batch_no % summary_freq_batches==0:\n",
        "            # TODO: add the loss of the training batch to the training summary\n",
        "            # YOUR CODE HERE\n",
        "            #print(f\"Epoch {epoch_no}, Batch {batch_no}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    running_loss=running_loss/len(train_loader)\n",
        "\n",
        "    print(f'Epoch {epoch_no} Training Loss--- {running_loss}')\n",
        "            #raise NotImplementedError()\n",
        "\n",
        "# Test on the train set (do not do this in practice)\n",
        "\n",
        "test_inputs = fashion_mnist.data.unsqueeze(1).float()  # [60000, 1, 28, 28]\n",
        "\n",
        "test_labels = fashion_mnist.targets\n",
        "\n",
        "test_predictions = None\n",
        "# TODO: feed test inputs, fetch predictions\n",
        "# YOUR CODE HERE\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "\n",
        "    # Get model outputs (logits)\n",
        "    test_outputs = model(test_inputs.float())\n",
        "\n",
        "    # Get the predicted class by finding the index of the maximum log-probability\n",
        "    # torch.max returns (values, indices), we only need the indices\n",
        "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
        "\n",
        "# Compute the accuracy of the validation predictions\n",
        "true_test_labels = test_labels\n",
        "print(\"\\nTest accuracy after training of {} iterations: {:.2f}%\".format(total_count, accuracy(true_test_labels, test_predictions)*100))\n",
        "\n",
        "# Random test sample\n",
        "sample_no = np.random.randint(0, len(test_inputs))\n",
        "print(\"\\nTest prediction: {}\".format(label_dict[test_predictions[sample_no].item()]))\n",
        "\n",
        "plt.show()\n",
        "plt.imshow(test_inputs[sample_no].reshape(28,28), cmap='Greys')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "yrJMvV0Yr9iF",
        "outputId": "21fb79bb-e0de-4d92-f4cc-46865143ea04"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss--- 1.4785935167630513\n",
            "Epoch 1 Training Loss--- 0.8525227451165517\n",
            "Epoch 2 Training Loss--- 0.7426238131046295\n",
            "Epoch 3 Training Loss--- 0.6867389276822408\n",
            "Epoch 4 Training Loss--- 0.6515599253177643\n",
            "Epoch 5 Training Loss--- 0.6265591427882512\n",
            "Epoch 6 Training Loss--- 0.6044438312212627\n",
            "Epoch 7 Training Loss--- 0.5907659406661987\n",
            "Epoch 8 Training Loss--- 0.5785014985720317\n",
            "Epoch 9 Training Loss--- 0.5671498588562012\n",
            "\n",
            "Test accuracy after training of 600000 iterations: 80.27%\n",
            "\n",
            "Test prediction: Ankle boot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3259583533.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  true_labels = torch.tensor(true_labels)\n",
            "/tmp/ipython-input-16-3259583533.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_labels = torch.tensor(predicted_labels)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}